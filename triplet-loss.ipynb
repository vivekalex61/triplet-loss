{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom keras import backend as K\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T07:58:16.110772Z","iopub.execute_input":"2022-04-27T07:58:16.111395Z","iopub.status.idle":"2022-04-27T07:58:18.740355Z","shell.execute_reply.started":"2022-04-27T07:58:16.111358Z","shell.execute_reply":"2022-04-27T07:58:18.739515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow \nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, AveragePooling1D,Lambda\nfrom tensorflow.keras import Model","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:14.847126Z","iopub.execute_input":"2022-04-27T07:58:14.847677Z","iopub.status.idle":"2022-04-27T07:58:15.156923Z","shell.execute_reply.started":"2022-04-27T07:58:14.847639Z","shell.execute_reply":"2022-04-27T07:58:15.156177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n(X_train, y_train), (X_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\nX_train = X_train.reshape(X_train.shape[0], 28,28,1)\nX_test = X_test.reshape(X_test.shape[0],28,28,1)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nx_train =X_train/255\nx_test =X_test/255","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:18.741972Z","iopub.execute_input":"2022-04-27T07:58:18.742436Z","iopub.status.idle":"2022-04-27T07:58:19.368918Z","shell.execute_reply.started":"2022-04-27T07:58:18.742398Z","shell.execute_reply":"2022-04-27T07:58:19.368162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating triplets \n#create (positive,anchor,negative)\n#create list of different labels\nimport random\n\ndef create_triplets(x_train,y_train,train=True):\n    pos_train=[]\n    neg_train=[]\n    anch_train=[]\n    df = pd.DataFrame(columns=['pos','anch','neg'])\n    triplets=[]\n    #lets 50 training example for 4 \n    if train == True:\n        sample=5000\n    else:\n        sample=400\n    train_pair=[]\n    labels=[0,1,2,3,4,5,6,7,8,9]\n    for label in labels:\n        \n        p=[i for i,x in enumerate(y_train) if x==label] \n        p_50=random.sample(p,sample)\n        p_50_img=list(x_train[p_50])\n        [pos_train.append(t) for t in p_50_img]\n        \n        a_50=random.sample(p,sample)\n        a_50_img=list(x_train[a_50])\n        [anch_train.append(t) for t in a_50_img]\n        \n        n=[i for i,x in enumerate(y_train) if x!=label]\n        n_50=random.sample(n,sample)\n        n_50_img=list(x_train[n_50])\n        [neg_train.append(t) for t in n_50_img]\n    return pos_train,anch_train,neg_train\n        #df.append({'pos':p_50_img,'anch': a_50_img,'neg': n_50_img}, ignore_index=True)\n\npos_train,anch_train,neg_train=create_triplets(x_train,y_train)\npos_test,anch_test,neg_test=create_triplets(x_test,y_test,train=False)\n         \n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:21.205123Z","iopub.execute_input":"2022-04-27T07:58:21.205398Z","iopub.status.idle":"2022-04-27T07:58:24.794595Z","shell.execute_reply.started":"2022-04-27T07:58:21.205367Z","shell.execute_reply":"2022-04-27T07:58:24.793795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataGen(tensorflow.keras.utils.Sequence):\n    def __init__(self,pos_train,anch_train,neg_train,batch_size):\n        self.pos=pos_train\n        self.anch=anch_train\n        self.neg=neg_train\n        self.batch_size=batch_size\n        self.n = len(self.pos)\n\n        \n    def __getitem__(self, index):\n        \n        pos = self.pos[index * self.batch_size:(index + 1) * self.batch_size]\n        anch=self.anch[index * self.batch_size:(index + 1) * self.batch_size]\n        neg=self.neg[index * self.batch_size:(index + 1) * self.batch_size]\n        label = np.ones(batch_size)\n        return [np.asarray(pos,dtype='float32'),np.asarray(anch,dtype='float32'),np.asarray(neg,dtype='float32')],label\n    def __len__(self):\n        return np.int(self.n // self.batch_size)\ntraingen=CustomDataGen(pos_train=pos_train,anch_train=anch_train,neg_train=neg_train,batch_size=8)\nevalgen =CustomDataGen(pos_train=pos_test,anch_train=anch_test,neg_train=neg_test,batch_size=8)       \n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:26.271774Z","iopub.execute_input":"2022-04-27T07:58:26.272221Z","iopub.status.idle":"2022-04-27T07:58:26.283814Z","shell.execute_reply.started":"2022-04-27T07:58:26.272183Z","shell.execute_reply":"2022-04-27T07:58:26.28292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-26T19:37:45.434845Z","iopub.execute_input":"2022-04-26T19:37:45.43514Z","iopub.status.idle":"2022-04-26T19:37:45.442227Z","shell.execute_reply.started":"2022-04-26T19:37:45.435109Z","shell.execute_reply":"2022-04-26T19:37:45.441055Z"}}},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D,ZeroPadding2D\nfrom tensorflow.keras.layers import Input, Lambda\n\n#from keras.datasets import mnist\nfrom tensorflow.keras import backend as K\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:29.61852Z","iopub.execute_input":"2022-04-27T07:58:29.618778Z","iopub.status.idle":"2022-04-27T07:58:30.361209Z","shell.execute_reply.started":"2022-04-27T07:58:29.618748Z","shell.execute_reply":"2022-04-27T07:58:30.360451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def triplet_loss(x, alpha = 0.2):\n    positive,anchor,negative = x\n    # distance between the anchor and the positive\n    dp = K.sum(K.square(anchor-positive),axis=1)\n    # distance between the anchor and the negative\n    dn = K.sum(K.square(anchor-negative),axis=1)\n    # compute loss\n    basic_loss = dp-dn+alpha\n    loss = K.maximum(basic_loss,0.0)\n    return loss\ndef identity_loss(y_true, y_pred):\n    return K.mean(y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:33.280759Z","iopub.execute_input":"2022-04-27T07:58:33.28106Z","iopub.status.idle":"2022-04-27T07:58:33.287052Z","shell.execute_reply.started":"2022-04-27T07:58:33.281028Z","shell.execute_reply":"2022-04-27T07:58:33.286351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='basemodel_plot.png', show_shapes=True, show_layer_names=True)\nplot_model(model2, to_file='tripletmodel_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:00:40.174491Z","iopub.execute_input":"2022-04-27T08:00:40.175415Z","iopub.status.idle":"2022-04-27T08:00:40.542021Z","shell.execute_reply.started":"2022-04-27T08:00:40.175368Z","shell.execute_reply":"2022-04-27T08:00:40.541201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 2 \nLR = 0.0005\nbatch_size=8\nalpha = 0.2 \ninput_shape=(28, 28,1)\ndef embedding_model():\n  # Simple convolutional model \n  # used for the embedding model.\n  input_shape=(28,28,1)\n  model = Sequential()\n  model.add(Convolution2D(32, (3, 3), activation='relu',\n                        input_shape=input_shape))\n  model.add(Convolution2D(32, (3, 3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5))\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(12))\n  return model\n\n\nmodel=embedding_model()\n\nP = Input(shape=input_shape, name = 'anchorPositive')\nenc_P = model(P)\nA = Input(shape=input_shape, name = 'anchor')\nenc_A = model(A)\nN = Input(shape=input_shape, name = 'anchorNegative')\nenc_N = model(N)\nloss = Lambda(triplet_loss)([enc_P,enc_A,enc_N]) \nmodel2 = Model(inputs=[P,A,N], outputs=loss)\nmodel2.compile(loss=identity_loss, optimizer=Adam(LR))\nhistory = model2.fit_generator(traingen,validation_data=evalgen,epochs=200, \n                    verbose=1,steps_per_epoch=20,validation_steps=30)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:58:46.543178Z","iopub.execute_input":"2022-04-27T07:58:46.543586Z","iopub.status.idle":"2022-04-27T07:59:55.842053Z","shell.execute_reply.started":"2022-04-27T07:58:46.54355Z","shell.execute_reply":"2022-04-27T07:59:55.841329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training and Validation Losses',size = 20)\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:01:55.189189Z","iopub.execute_input":"2022-04-27T08:01:55.189792Z","iopub.status.idle":"2022-04-27T08:01:55.418839Z","shell.execute_reply.started":"2022-04-27T08:01:55.189752Z","shell.execute_reply":"2022-04-27T08:01:55.418138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('triplet_loss.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T06:40:49.449551Z","iopub.execute_input":"2022-04-27T06:40:49.450133Z","iopub.status.idle":"2022-04-27T06:40:49.476056Z","shell.execute_reply.started":"2022-04-27T06:40:49.450096Z","shell.execute_reply":"2022-04-27T06:40:49.475396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_size = 500\n\nX_test = model.predict(x_test[:sample_size].reshape(-1,28,28,1))\ny_test=y_test[:sample_size]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:02:20.151376Z","iopub.execute_input":"2022-04-27T08:02:20.15212Z","iopub.status.idle":"2022-04-27T08:02:20.343062Z","shell.execute_reply.started":"2022-04-27T08:02:20.152079Z","shell.execute_reply":"2022-04-27T08:02:20.342311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne=TSNE()\ntest_tsne_embeds = tsne.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:02:24.31072Z","iopub.execute_input":"2022-04-27T08:02:24.311339Z","iopub.status.idle":"2022-04-27T08:02:26.725733Z","shell.execute_reply.started":"2022-04-27T08:02:24.311295Z","shell.execute_reply":"2022-04-27T08:02:26.725102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as PathEffects\nimport pandas as pd\n\n\ndef scatter(x, labels, subtitle=None):\n    # Create a scatter plot of all the \n    # the embeddings of the model.\n    # We choose a color palette with seaborn.\n    palette = np.array(sns.color_palette(\"hls\", 10))\n    # We create a scatter plot.\n    f = plt.figure(figsize=(8, 8))\n    ax = plt.subplot(aspect='equal')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0,alpha = 0.5, s=40,\n                    c=palette[labels.astype(np.int)] )\n    plt.xlim(-25, 25)\n    plt.ylim(-25, 25)\n    ax.axis('off')\n    ax.axis('tight')\n    \n    \n\nscatter(test_tsne_embeds, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:02:30.01191Z","iopub.execute_input":"2022-04-27T08:02:30.012921Z","iopub.status.idle":"2022-04-27T08:02:30.450243Z","shell.execute_reply.started":"2022-04-27T08:02:30.012873Z","shell.execute_reply":"2022-04-27T08:02:30.449602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}